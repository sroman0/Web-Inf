{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T14:15:04.708116600Z",
     "start_time": "2024-04-16T14:15:04.485082300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow\n",
    "import keras\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "#\n",
    "#import demoji\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#from tensorflow.keras import models\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Embedding\n",
    "#from keras.layers import Flatten\n",
    "#from keras.layers import Dense\n",
    "#from tensorflow.keras import layers\n",
    "#from tensorflow.keras import callbacks\n",
    "#from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T13:35:44.449388Z",
     "start_time": "2024-04-16T13:32:58.039860300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T09:51:23.642158800Z",
     "start_time": "2024-04-14T09:51:23.637157800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NB_WORDS = 10000 # Parameter indicating the number of words we'll put in the dictionary\n",
    "NB_EPOCHS = 5 # Number of epochs we usually start to train with\n",
    "BATCH_SIZE = 32 # Size of the batches used in the mini-batch gradient descent\n",
    "MAX_LEN = 100 # Maximum number of words in a sequence\n",
    "FILTER_STRING='!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n'\n",
    "EMBEDDING_SIZE=100 # Size of the word embedding\n",
    "PATIENCE=10 # Patience level\n",
    "DROP_RATE=0.4 # Dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.640159Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def transformText(text):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    #Delete emoji\n",
    "    text = demoji.replace(text, \"\")\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    # Removing all the stopwords\n",
    "    filtered_words = [word for word in text.split() if word not in stops]\n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation(text)\n",
    "    # Strip all the numerics\n",
    "    text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "    # Removing all the words with < 3 characters\n",
    "    text = gensim.parsing.preprocessing.strip_short(text, minsize=3)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    # Stemming\n",
    "    return gensim.parsing.preprocessing.stem_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.643163600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset= pd.read_csv('train_40k.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T09:51:23.646159500Z",
     "start_time": "2024-04-14T09:51:23.646159500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#explorative analysis\n",
    "print('\\nData shape')\n",
    "print(dataset.shape)\n",
    "print('\\nData describe')\n",
    "print(dataset.describe())\n",
    "print('\\nData dtypes')\n",
    "print(dataset.dtypes)\n",
    "print('\\nCount Nan')\n",
    "print(dataset.isna().sum())\n",
    "print('\\nVerify values of variable target')\n",
    "print(dataset['Cat1'].unique())\n",
    "print('\\nCount values of variable target')\n",
    "print(dataset['Cat1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.649536800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features_to_drop = ['Title', 'userId', 'Helpfulness', 'Score', 'Time','Cat2'\n",
    "                    ,'Cat3']\n",
    "dataset = dataset.drop(features_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.652536700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#applies transformText to all rows of text\n",
    "dataset['Text'] = dataset['Text'].map(transformText)\n",
    "print(dataset['Text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.653537400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "numero_classi=dataset['Cat1'].nunique()\n",
    "numero_classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.656536700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "dataset['Cat1'] = label_encoder.fit_transform(dataset['Cat1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.659537400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#operiamo un train test\n",
    "X_trainAll, X_test, y_trainAll, y_test = train_test_split(dataset['Text'], dataset['Cat1'],\n",
    "                                                          test_size=0.10, random_state=10)\n",
    "print (\"Training Sample Size:\", len(X_trainAll), ' ', \"Test Sample Size:\" ,len(X_test))\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainAll, y_trainAll,\n",
    "                                                          test_size=0.20, random_state=10)\n",
    "print (\"Training Sample Size:\", len(X_train), ' ', \"Validation Sample Size:\" ,len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.663537600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizzazione del testo\n",
    "tokenizer = Tokenizer(num_words=NB_WORDS ,filters=FILTER_STRING , oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "voc_len=len(tokenizer.word_index)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_valid_seq = tokenizer.texts_to_sequences(X_valid)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "voc_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.665536200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Padding delle sequenze\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=100)\n",
    "X_valid_padded=pad_sequences(X_valid_seq, maxlen=100)\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.667537Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Costruzione del modello\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_len+1, 100, input_length=100))\n",
    "model.add(layers.Dropout(DROP_RATE))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(DROP_RATE))\n",
    "model.add(Dense(numero_classi+1, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.669536100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Addestramento del modello\n",
    "history = model.fit(X_train_padded, y_train, epochs=NB_EPOCHS,\n",
    "                    validation_data=(X_valid_padded, y_valid),batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T09:51:23.723554300Z",
     "start_time": "2024-04-14T09:51:23.670537300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_train_padded, y_train)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-14T09:51:23.671536300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test_padded), axis=-1)\n",
    "confusion_mtx = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
